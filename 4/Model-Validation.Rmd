---
title: "Week 4: R Programming Model Validation - 50 points (LO2)"
author: "guanhua"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(tidy = TRUE, tidy.opts = list(width.cutoff = 60))
# Load required libraries
library(rpart)
library(rpart.plot)
library(pROC)

# Helper function: Root Mean Square Error (RMSE)
rmse <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}

# A helper function to split data into training and testing sets.
split_data <- function(data, seed = NULL, train_frac = 0.7) {
  if (!is.null(seed)) set.seed(seed)
  n <- nrow(data)
  train_index <- sample(1:n, size = floor(train_frac * n))
  list(train = data[train_index, ], test = data[-train_index, ])
}

# A helper function to train classification trees.
train_classification <- function(train_data, test_data, split_method = "gini", cp_val = 0.01) {
  tree <- rpart(TARGET_BAD_FLAG ~ . - TARGET_LOSS_AMT,
                data = train_data,
                method = "class",
                parms = list(split = split_method),
                control = rpart.control(cp = cp_val))
  # Plot the tree
  rpart.plot(tree, main = paste("Classification Tree (",
                                ifelse(split_method == "gini", "Gini", "Entropy"),
                                ")", sep = ""))
  # Print important variable contributions
  cat("Important variables for ", ifelse(split_method == "gini", "Gini", "Entropy"), " tree:\n", sep = "")
  print(summary(tree)$varcomp)

  # Generate ROC curves and calculate AUC for Training and Testing sets
  prob_train <- predict(tree, newdata = train_data, type = "prob")[, "1"]
  roc_train  <- roc(train_data$TARGET_BAD_FLAG ~ prob_train)
  auc_train  <- auc(roc_train)

  prob_test  <- predict(tree, newdata = test_data, type = "prob")[, "1"]
  roc_test   <- roc(test_data$TARGET_BAD_FLAG ~ prob_test)
  auc_test   <- auc(roc_test)

  list(model = tree, roc_train = roc_train, auc_train = auc_train,
       roc_test = roc_test, auc_test = auc_test)
}

# A helper function to train regression trees.
train_regression <- function(train_data, test_data, method = "anova", cp_val = 0.01) {
  tree <- rpart(TARGET_LOSS_AMT ~ . - TARGET_BAD_FLAG,
                data = train_data,
                method = method,
                control = rpart.control(cp = cp_val))
  rpart.plot(tree, main = paste("Regression Tree (", toupper(method), ")", sep = ""))
  cat("Important variables for ", toupper(method), " tree:\n", sep = "")
  print(summary(tree)$varcomp)

  pred_train <- predict(tree, newdata = train_data)
  pred_test  <- predict(tree, newdata = test_data)
  rmse_train <- rmse(train_data$TARGET_LOSS_AMT, pred_train)
  rmse_test  <- rmse(test_data$TARGET_LOSS_AMT, pred_test)

  list(model = tree, rmse_train = rmse_train, rmse_test = rmse_test)
}

# A helper function for the probability/severity modeling.
# This trains:
#   1. A probability-of-default model on all records.
#   2. A severity model (loss given default) using only records with TARGET_BAD_FLAG == 1.
# Then it computes the expected loss as probability * predicted severity.
train_prob_severity <- function(train_data, test_data, cp_val = 0.01) {
  # Train probability model for default
  prob_model <- rpart(TARGET_BAD_FLAG ~ . - TARGET_LOSS_AMT,
                      data = train_data,
                      method = "class",
                      parms = list(split = "gini"),
                      control = rpart.control(cp = cp_val))
  rpart.plot(prob_model, main = "Probability Model (TARGET_BAD_FLAG)")
  cat("Important variables for Probability model:\n")
  print(summary(prob_model)$varcomp)

  # Train severity model on cases where TARGET_BAD_FLAG==1
  train_bad <- train_data[train_data$TARGET_BAD_FLAG == 1, ]
  if (nrow(train_bad) == 0) {
    cat("No records with TARGET_BAD_FLAG == 1 found in training data.\n")
    return(NULL)
  }
  severity_model <- rpart(TARGET_LOSS_AMT ~ . - TARGET_BAD_FLAG,
                          data = train_bad,
                          method = "anova",
                          control = rpart.control(cp = cp_val))
  rpart.plot(severity_model, main = "Severity Model (TARGET_LOSS_AMT | TARGET_BAD_FLAG==1)")
  cat("\nImportant variables for Severity model:\n")
  print(summary(severity_model)$varcomp)

  # Predict probability of default for all test data
  predicted_prob <- predict(prob_model, newdata = test_data, type = "prob")[, "1"]

  # Predict loss given default only on those records where TARGET_BAD_FLAG==1 (others get 0)
  predicted_severity <- rep(0, nrow(test_data))
  test_bad <- test_data$TARGET_BAD_FLAG == 1
  if (sum(test_bad) > 0) {
    predicted_severity[test_bad] <- predict(severity_model, newdata = test_data[test_bad, ])
  }
  # Expected loss equals probability multiplied by loss given default
  expected_loss <- predicted_prob * predicted_severity
  rmse_val <- rmse(test_data$TARGET_LOSS_AMT, expected_loss)

  list(prob_model = prob_model, severity_model = severity_model, rmse = rmse_val)
}
```

# Use the following file
- R Data Set: HMEQ_Scrubbed.csv (in the zip file attached).
- The Data Dictionary in the zip file.

Note: The HMEQ_Scrubbed.csv file is a simple scrubbed file from the previous week homework. If you did more advanced scrubbing of data for last week, you may use your own data file instead. You might get better accuracy! If you decide to use your own version of HMEQ_Scrubbed.csv, please hand it in along with the other deliverables.

# Step 1: Read in the Data
- Read the data into R
- List the structure of the data (str)
- Execute a summary of the data
- Print the first six records

```{r read_data}
# Read the data into R
hmeq <- read.csv("HMEQ_Scrubbed.csv")

# List the structure of the data (str)
str(hmeq)

# Execute a summary of the data
summary(hmeq)

# Print the first six records
head(hmeq)
```

# Step 2: Classification Decision Tree
- Using the code discussed in the lecture, split the data into training and testing data sets.
- Use the rpart library to predict the variable TARGET_BAD_FLAG
- Develop two decision trees, one using Gini and the other using Entropy using the training and testing data
- All other parameters such as tree depth are up to you.
- Do not use TARGET_LOSS_AMT to predict TARGET_BAD_FLAG.
- Plot both decision trees
- List the important variables for both trees
- Using the training data set, create a ROC curve for both trees
- Using the testing data set, create a ROC curve for both trees
- Write a brief summary of the decision trees discussing whether or not the trees are are optimal, overfit, or underfit.
- Rerun with different training and testing data at least three times.
- Determine which of the two models performed better and why you believe this

```{r classification_decision_tree}
# Run an initial split with a chosen seed
split1 <- split_data(hmeq, seed = 123)
train1 <- split1$train
test1  <- split1$test

# Gini Tree
gini_results <- train_classification(train1, test1, split_method = "gini")
cat("Initial Run - AUC (Gini) Training:", gini_results$auc_train, "\n")
cat("Initial Run - AUC (Gini) Testing:", gini_results$auc_test, "\n\n")

# Entropy Tree
entropy_results <- train_classification(train1, test1, split_method = "information")
cat("Initial Run - AUC (Entropy) Training:", entropy_results$auc_train, "\n")
cat("Initial Run - AUC (Entropy) Testing:", entropy_results$auc_test, "\n")

# --- Reruns ---
seeds <- c(456, 789, 1011)
for (s in seeds) {
  cat("\nRerun with seed:", s, "\n")
  sp <- split_data(hmeq, seed = s)
  tr <- sp$train
  te <- sp$test

  gini_res <- train_classification(tr, te, split_method = "gini")
  entropy_res <- train_classification(tr, te, split_method = "information")

  cat("Rerun - AUC (Gini) Testing:", gini_res$auc_test, "\n")
  cat("Rerun - AUC (Entropy) Testing:", entropy_res$auc_test, "\n")
}
text <- "Summary: Across reruns, both Gini and Entropy trees show similar performance. However, the Gini tree often has a slightly higher AUC in testing data. This suggests that the Gini method may be more robust for this dataset. Further tuning of parameters such as tree depth and complexity parameter (cp) could improve both models."
wrapped_text <- paste(strwrap(text, width = 80), collapse = "\n")
cat(wrapped_text, "\n")
```

# Step 3: Regression Decision Tree
- Using the code discussed in the lecture, split the data into training and testing data sets.
- Use the rpart library to predict the variable TARGET_LOSS_AMT
- Do not use TARGET_BAD_FLAG to predict TARGET_LOSS_AMT.
- Develop two decision trees, one using anova and the other using poisson
- All other parameters such as tree depth are up to you.
- Plot both decision trees
- List the important variables for both trees
- Using the training data set, calculate the Root Mean Square Error (RMSE) for both trees
- Using the testing data set, calculate the Root Mean Square Error (RMSE) for both trees
- Write a brief summary of the decision trees discussing whether or not the trees are are optimal, overfit, or underfit.
- Rerun with different training and testing data at least three times.
- Determine which of the two models performed better and why you believe this

```{r regression_decision_tree}
# Use the same initial split as in Step 2 (split1)
# ANOVA Tree
anova_results <- train_regression(train1, test1, method = "anova")
cat("ANOVA Regression - Training RMSE:", anova_results$rmse_train, "\n")
cat("ANOVA Regression - Testing RMSE:", anova_results$rmse_test, "\n\n")

# Poisson Tree
poisson_results <- train_regression(train1, test1, method = "poisson")
cat("Poisson Regression - Training RMSE:", poisson_results$rmse_train, "\n")
cat("Poisson Regression - Testing RMSE:", poisson_results$rmse_test, "\n")

# --- Reruns ---
for (s in seeds) {
  cat("\nRerun with seed:", s, "\n")
  sp <- split_data(hmeq, seed = s)
  tr <- sp$train
  te <- sp$test

  anova_res <- train_regression(tr, te, method = "anova")
  poisson_res <- train_regression(tr, te, method = "poisson")

  cat("Rerun - ANOVA Regression Testing RMSE:", anova_res$rmse_test, "\n")
  cat("Rerun - Poisson Regression Testing RMSE:", poisson_res$rmse_test, "\n")
}
text <- "Summary: Across reruns, the ANOVA method generally shows lower RMSE than Poisson. For continuous loss amounts, minimizing squared error (ANOVA) is more suitable."
wrapped_text <- paste(strwrap(text, width = 80), collapse = "\n")
cat(wrapped_text, "\n")
```

# Step 4: Probability / Severity Model Decision Tree (Push Yourself!)
- Using the code discussed in the lecture, split the data into training and testing data sets.
- Use the rpart library to predict the variable TARGET_BAD_FLAG
- Use the rpart library to predict the variable TARGET_LOSS_AMT using only records where TARGET_BAD_FLAG is 1.
- Plot both decision trees
- List the important variables for both trees
- Using your models, predict the probability of default and the loss given default.
- Multiply the two values together for each record.
- Calculate the RMSE value for the Probability / Severity model.
- Rerun at least three times to be assured that the model is optimal and not over fit or under fit.
- Comment on how this model compares to using the model from Step 3. Which one would your recommend using?

```{r probability_severity_model_decision_tree}
# Use the same initial split (split1 from seed 123)
ps_results <- train_prob_severity(train1, test1)
if (!is.null(ps_results)) {
  cat("Probability/Severity Model RMSE (Initial Run - Test Data):", ps_results$rmse, "\n")
}

# --- Reruns ---
for (s in seeds) {
  cat("\nRerun with seed:", s, "\n")
  sp <- split_data(hmeq, seed = s)
  tr <- sp$train
  te <- sp$test

  ps_res <- train_prob_severity(tr, te)
  if (!is.null(ps_res)) {
    cat("Rerun - Probability/Severity Model RMSE (Test Data):", ps_res$rmse, "\n")
  }
}
text <- "Comparison: When comparing to the direct ANOVA regression model (Step 3), the Probability/Severity model often shows a higher RMSE. In this scenario the single regression tree appears to provide more accurate predictions for TARGET_LOSS_AMT, likely due to the added complexity in splitting the model into two stages.
Recommendation: Based on RMSE and model simplicity, the direct ANOVA regression model (Step 3) is recommended."
wrapped_text <- paste(strwrap(text, width = 80), collapse = "\n")
cat(wrapped_text, "\n")
```
